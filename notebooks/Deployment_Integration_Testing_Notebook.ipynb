{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Deployment and Integration Testing\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook tests the complete system integration and deployment readiness:\\n\",\n",
    "    \"- API endpoint testing\\n\",\n",
    "    \"- Performance benchmarking\\n\",\n",
    "    \"- MongoDB integration\\n\",\n",
    "    \"- Pipeline orchestration\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"import requests\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from pymongo import MongoClient\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.database.mongo.connection import get_database\\n\",\n",
    "    \"from src.database.mongo.queries import insert_attendance_record, get_employee_records\\n\",\n",
    "    \"from src.pipeline.model_pipeline import ModelPipeline\\n\",\n",
    "    \"from src.pipeline.result_aggregator import ResultAggregator\\n\",\n",
    "    \"from src.utils.logging import setup_logger\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Setup logging\\n\",\n",
    "    \"logger = setup_logger('deployment_testing')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. API Endpoint Testing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def test_api_endpoints(base_url='http://localhost:8000'):\\n\",\n",
    "    \"    endpoints = {\\n\",\n",
    "    \"        'health': '/health',\\n\",\n",
    "    \"        'predict': '/api/v1/predict',\\n\",\n",
    "    \"        'employees': '/api/v1/employees',\\n\",\n",
    "    \"        'attendance': '/api/v1/attendance'\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results = []\\n\",\n",
    "    \"    for name, endpoint in endpoints.items():\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            start_time = time.time()\\n\",\n",
    "    \"            response = requests.get(f'{base_url}{endpoint}')\\n\",\n",
    "    \"            latency = time.time() - start_time\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            results.append({\\n\",\n",
    "    \"                'endpoint': name,\\n\",\n",
    "    \"                'status_code': response.status_code,\\n\",\n",
    "    \"                'latency': latency,\\n\",\n",
    "    \"                'success': response.status_code == 200\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            logger.error(f'Error testing endpoint {name}: {str(e)}')\\n\",\n",
    "    \"            results.append({\\n\",\n",
    "    \"                'endpoint': name,\\n\",\n",
    "    \"                'status_code': None,\\n\",\n",
    "    \"                'latency': None,\\n\",\n",
    "    \"                'success': False,\\n\",\n",
    "    \"                'error': str(e)\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return pd.DataFrame(results)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Performance Benchmarking\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def benchmark_pipeline(test_images, n_iterations=10):\\n\",\n",
    "    \"    pipeline = ModelPipeline()\\n\",\n",
    "    \"    metrics = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for img_path in test_images:\\n\",\n",
    "    \"        img_metrics = []\\n\",\n",
    "    \"        for _ in range(n_iterations):\\n\",\n",
    "    \"            start_time = time.time()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Measure each step\\n\",\n",
    "    \"            t0 = time.time()\\n\",\n",
    "    \"            faces = pipeline.detect_faces(img_path)\\n\",\n",
    "    \"            t1 = time.time()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            features = pipeline.extract_features(faces)\\n\",\n",
    "    \"            t2 = time.time()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            predictions = pipeline.predict(features)\\n\",\n",
    "    \"            t3 = time.time()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            img_metrics.append({\\n\",\n",
    "    \"                'image': img_path,\\n\",\n",
    "    \"                'detection_time': t1 - t0,\\n\",\n",
    "    \"                'feature_extraction_time': t2 - t1,\\n\",\n",
    "    \"                'prediction_time': t3 - t2,\\n\",\n",
    "    \"                'total_time': t3 - t0,\\n\",\n",
    "    \"                'faces_detected': len(faces)\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        metrics.extend(img_metrics)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return pd.DataFrame(metrics)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. MongoDB Integration Testing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def test_database_integration():\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Test connection\\n\",\n",
    "    \"        db = get_database()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Test write operations\\n\",\n",
    "    \"        test_record = {\\n\",\n",
    "    \"            'employee_id': 'test_employee',\\n\",\n",
    "    \"            'timestamp': time.time(),\\n\",\n",
    "    \"            'status': 'present'\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"        insert_result = insert_attendance_record(test_record)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Test read operations\\n\",\n",
    "    \"        records = get_employee_records('test_employee')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return {\\n\",\n",
    "    \"            'connection_success': True,\\n\",\n",
    "    \"            'write_success': insert_result is not None,\\n\",\n",
    "    \"            'read_success': len(records) > 0\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        logger.error(f'Database integration test failed: {str(e)}')\\n\",\n",
    "    \"        return {\\n\",\n",
    "    \"            'connection_success': False,\\n\",\n",
    "    \"            'write_success': False,\\n\",\n",
    "    \"            'read_success': False,\\n\",\n",
    "    \"            'error': str(e)\\n\",\n",
    "    \"        }\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. System Load Testing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def load_test_api(base_url, n_requests=100, concurrent=10):\\n\",\n",
    "    \"    import concurrent.futures\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def make_request():\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            start_time = time.time()\\n\",\n",
    "    \"            response = requests.post(\\n\",\n",
    "    \"                f'{base_url}/api/v1/predict',\\n\",\n",
    "    \"                files={'image': open('path/to/test/image.jpg', 'rb')}\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            return {\\n\",\n",
    "    \"                'success': response.status_code == 200,\\n\",\n",
    "    \"                'latency': time.time() - start_time,\\n\",\n",
    "    \"                'status_code': response.status_code\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            return {\\n\",\n",
    "    \"                'success': False,\\n\",\n",
    "    \"                'latency': None,\\n\",\n",
    "    \"                'error': str(e)\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results = []\\n\",\n",
    "    \"    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent) as executor:\\n\",\n",
    "    \"        futures = [executor.submit(make_request) for _ in range(n_requests)]\\n\",\n",
    "    \"        for future in concurrent.futures.as_completed(futures):\\n\",\n",
    "    \"            results.append(future.result())\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return pd.DataFrame(results)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. End-to-End Pipeline Test\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def test_end_to_end_pipeline(test_image_path):\\n\",\n",
    "    \"    pipeline = ModelPipeline()\\n\",\n",
    "    \"    aggregator = ResultAggregator()\\n\",\n",
    "    \"    \\n    try:\\n\",\n",
    "    \"        # Process image through pipeline\\n\",\n",
    "    \"        faces = pipeline.detect_faces(test_image_path)\\n\",\n",
    "    \"        features = pipeline.extract_features(faces)\\n\",\n",
    "    \"        predictions = pipeline.predict(features)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Aggregate results\\n\",\n",
    "    \"        final_results = aggregator.combine_results(predictions)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Store results in database\\n\",\n",
    "    \"        db = get_database()\\n\",\n",
    "    \"        for result in final_results:\\n\",\n",
    "    \"            insert_attendance_record({\\n\",\n",
    "    \"                'employee_id': result['employee_id'],\\n\",\n",
    "    \"                'timestamp': time.time(),\\n\",\n",
    "    \"                'confidence': result['confidence'],\\n\",\n",
    "    \"                'additional_metrics': result['metrics']\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return {\\n\",\n",
    "    \"            'success': True,\\n\",\n",
    "    \"            'faces_detected': len(faces),\\n\",\n",
    "    \"            'predictions_made': len(predictions),\\n\",\n",
    "    \"            'results_stored': len(final_results)\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        logger.error(f'End-to-end pipeline test failed: {str(e)}')\\n\",\n",
    "    \"        return {\\n\",\n",
    "    \"            'success': False,\\n\",\n",
    "    \"            'error': str(e)\\n\",\n",
    "    \"        }\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
